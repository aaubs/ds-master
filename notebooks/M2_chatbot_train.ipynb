{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOT7l8MFKdfH0tc/gPKr3na",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaubs/ds-master/blob/main/notebooks/M2_chatbot_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple FAQ chatbot\n",
        "\n",
        "![](https://source.unsplash.com/V5vqWC9gyEU)\n",
        "\n",
        "This is a variation of https://github.com/python-engineer/pytorch-chatbot, and a toy-example.\n",
        "For a more complex example check out (e.g.) https://github.com/MrJay10/banking-faq-bot. Datacamp has some courses on that topic, too.\n",
        "\n",
        "The data needed for building such a system is a collection from a company FAQ for instance with variations for each question-answer pair type. For examples with many q-a pairs like the banking-faq, you can consider similarity-based approaches, where input text is matched with most \"similar\" predifined questions and then the user picks upon request - \"did you mean xyz-question\"\n",
        "Alternatively, one could create paraphrased versions of questions for each question-answer pair to have more training examples. This can be done manually or \n",
        "\n",
        "The overall architecture is as follows:\n",
        "\n",
        "*   Given a free text/prompt, predict which question is asked (intent)\n",
        "*   Pick corresponding answer (e.g. random out of 2-3) to simulate dialogue\n",
        "\n",
        "In this notebook, we will first use TFIDF-Logit, then standard SpaCy vectors and finally Floret (new SpaCy vectors that combine a new efficient compression with fastText, that helps overcome typos by including subword-elements in the model)\n"
      ],
      "metadata": {
        "id": "wyxDgeviYAWi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O18yPl__dtpc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utils...\n",
        "import json\n",
        "import requests\n",
        "import random"
      ],
      "metadata": {
        "id": "UG0NwwC9JS9z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will be using the medium-sized spacy model here"
      ],
      "metadata": {
        "id": "Nth-mmRSaAue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! spacy download en_core_web_md --quiet"
      ],
      "metadata": {
        "id": "WUQklcMMOAqa",
        "outputId": "d0808c0e-a633-4bec-89db-a8276e4c7e76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-01 13:50:30.589015: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42.8 MB 66.2 MB/s \n",
            "\u001b[?25h\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy #spacy for quick language prepro\n",
        "nlp = spacy.load('en_core_web_md') #instantiating English module"
      ],
      "metadata": {
        "id": "ocLVwJT6eJfy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline #pipeline creation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer #transforms text to sparse matrix\n",
        "from sklearn.linear_model import LogisticRegression #Logit model"
      ],
      "metadata": {
        "id": "XoLr_SehePR0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we use spacy for preprocessing"
      ],
      "metadata": {
        "id": "VJzNOJjKaF6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_prepro(texts):\n",
        "  \"\"\"\n",
        "  takes in a list/iterable of texts\n",
        "  removes twitter stuff\n",
        "  lowercases, normalizes text\n",
        "  \"\"\"\n",
        "\n",
        "  clean_container = []\n",
        "\n",
        "  for text in nlp.pipe(texts, disable=[\"parser\", \"ner\"]):\n",
        "\n",
        "    txt = [token.lemma_.lower() for token in text # lemmatize and lower\n",
        "          if token.is_alpha # remove numbers\n",
        "          and not token.is_punct] # remove punctoation\n",
        "\n",
        "    clean_container.append(\" \".join(txt))\n",
        "  \n",
        "  return clean_container"
      ],
      "metadata": {
        "id": "Cc87yUzfflkc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is a json-file with questions and answers as well as \"intent-tags\"\n",
        "We can open it from local or grab it from remote with requests (only one option).\n",
        "The reasonn for using a json here is that variations of questions and answers are independent (number/linking; n-n). e.g. you can have 2 ways to ask and 4 ways to answer for a specific issue."
      ],
      "metadata": {
        "id": "CqR6QJ99aL9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#open loacal file\n",
        "# data = json.load(open('chatbot-convo.json','r'))"
      ],
      "metadata": {
        "id": "Afc5iEBTf7vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stream file from remote online\n",
        "r = requests.get('https://github.com/aaubs/ds-master/raw/main/data/chatbot-convo.json')\n",
        "data = json.loads(r.text)"
      ],
      "metadata": {
        "id": "avU96skeH818"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For training, we need to get all questions and associated labels into tabular format. We iterate over all intents in the data and zip them with the intent-label into a list of tupels. Zip is a great function to bind 2 lists into a list of tupels `[a,b,c], [1,2,3] â†’ [(a,1), (b,2), (c,3)]`\n",
        "we multiply the label `l*[i['tag']]` to reach `len(i['patterns']) == len(l*[i['tag']])`"
      ],
      "metadata": {
        "id": "Od_NcosWayl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training = []\n",
        "\n",
        "for i in data['intents']:\n",
        "  l = len(i['patterns'])\n",
        "  tuples = list(zip(i['patterns'], l*[i['tag']])) \n",
        "  training.extend(tuples)\n"
      ],
      "metadata": {
        "id": "nWaCHVx_gdyC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_df = pd.DataFrame(training, columns=['txt','label'])"
      ],
      "metadata": {
        "id": "O7bGagjbgenf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_df"
      ],
      "metadata": {
        "id": "Ccuz4f8Zf-u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_df.txt_p = text_prepro(training_df.txt)"
      ],
      "metadata": {
        "id": "uoisfhHSiBS1",
        "outputId": "906340d7-fa3c-4aa7-ffec-07d1eb25edb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiate models and \"bundle up as pipeline\"\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "cls = LogisticRegression()\n",
        "\n",
        "pipe = make_pipeline(tfidf, cls)"
      ],
      "metadata": {
        "id": "6ogumcNqiKDM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.fit(training_df.txt_p, training_df.label)"
      ],
      "metadata": {
        "id": "UjbAC947ilWU",
        "outputId": "efc496ee-30f0-4695-eeb6-44568d19d006",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
              "                ('logisticregression', LogisticRegression())])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.predict(['tell me something funny'])"
      ],
      "metadata": {
        "id": "uHK4GHj2jJL6",
        "outputId": "706a6200-fd9f-4e93-b8f0-aa7c3bb748cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['funny'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's give our bot a name\n",
        "bot_name = 'ðŸ’¬ Hugo'"
      ],
      "metadata": {
        "id": "TU6B3CZbk0Uj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input triggers reply, which preprocesses the text, asks the model for a prediction (which class of question?), then iterates over all possible intent-types and where it finds a match, it retrieves a random response from this class."
      ],
      "metadata": {
        "id": "Q34db35tbpio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reply(txt):\n",
        "  clean_text = text_prepro([txt])\n",
        "  tag = pipe.predict(clean_text)[0]\n",
        "  for intent in data['intents']:\n",
        "    if tag == intent[\"tag\"]:\n",
        "      print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n"
      ],
      "metadata": {
        "id": "8FyKHuP2jv_7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply('Tell me a joke')"
      ],
      "metadata": {
        "id": "OD4vca4slXxL",
        "outputId": "8ae6c4e8-5454-41db-ccbd-586338217164",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ’¬ Hugo: Why did the hipster burn his mouth? He drank the coffee before it was cool.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using SpaCy for vectorization\n",
        "Using \"traditional\" spacy embeddings. Medium web model.\n",
        "When using spacy, we rely on pretrained vectors i.e. spacy takes care of all preprocessing and vectorization internally. Thus, we can skip TFIDF and go directly to model training."
      ],
      "metadata": {
        "id": "3HNti4NsJZFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we use again logistic regression\n",
        "model_spacy = LogisticRegression()"
      ],
      "metadata": {
        "id": "_1E9nP1LIi0z"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_df.head(10)"
      ],
      "metadata": {
        "id": "fdZdevGKJr4L",
        "outputId": "d92aaa0d-bab5-4d2e-d014-1a36419024f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                txt     label\n",
              "0                Hi  greeting\n",
              "1               Hey  greeting\n",
              "2       How are you  greeting\n",
              "3  Is anyone there?  greeting\n",
              "4             Hello  greeting\n",
              "5          Good day  greeting\n",
              "6               Bye   goodbye\n",
              "7     See you later   goodbye\n",
              "8           Goodbye   goodbye\n",
              "9            Thanks    thanks"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5acdaed-08f8-4952-975e-b8a34b66371a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txt</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hey</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How are you</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Is anyone there?</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hello</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Good day</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Bye</td>\n",
              "      <td>goodbye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>See you later</td>\n",
              "      <td>goodbye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Goodbye</td>\n",
              "      <td>goodbye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Thanks</td>\n",
              "      <td>thanks</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5acdaed-08f8-4952-975e-b8a34b66371a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b5acdaed-08f8-4952-975e-b8a34b66371a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b5acdaed-08f8-4952-975e-b8a34b66371a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we grab the vectors for all texts and stack them into a matrix\n",
        "X_train = np.vstack([txt.vector for txt in nlp.pipe(training_df.txt, disable=[\"parser\", \"ner\"])])"
      ],
      "metadata": {
        "id": "BxKLgpKzJzLr"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quick explaininng of the vectors (not really part of the code)\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cosine_similarity(X_train)[0]"
      ],
      "metadata": {
        "id": "D1EcQ14iKwMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "model_spacy.fit(X_train, training_df.label)"
      ],
      "metadata": {
        "id": "hEjzytCVKUhn",
        "outputId": "71051f44-8308-4db3-86ea-30f1af0bc429",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bot_name = 'ðŸ’¬ SpaCy Hugo'"
      ],
      "metadata": {
        "id": "xeJB2B94Kd9s"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reply_spacy(txt):\n",
        "  tag = model_spacy.predict([nlp(txt).vector])[0]\n",
        "  for intent in data['intents']:\n",
        "    if tag == intent[\"tag\"]:\n",
        "      print(f\"{bot_name}: {random.choice(intent['responses'])}\")"
      ],
      "metadata": {
        "id": "jy3uPsUyMLYd"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply_spacy('how can I pay?')"
      ],
      "metadata": {
        "id": "K0j-ew5kMXga",
        "outputId": "d07adb31-eed4-437f-899e-f57d2e7bcfcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ’¬ SpaCy Hugo: We accept VISA, Mastercard and Paypal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trying out Floret ðŸŒ¸\n",
        "In 2017 Facebook introduced [fastText](https://fasttext.cc/) that includes sub-word elements in the model creation. In April 2022 Explorion.ai presented Blom Embeddings - an elegant way to reduce embessing size. Later In August 2022 they introduced [floret](https://explosion.ai/blog/floret-vectors), an approach to jon fastText with Bloom (not related to https://huggingface.co/bigscience/bloom)."
      ],
      "metadata": {
        "id": "hB3KPlztOqEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get floret installed\n",
        "! python -m pip install floret 'spacy~=3.4.0' --quiet"
      ],
      "metadata": {
        "id": "ZE40R9dNOXYi",
        "outputId": "ae8ec706-65a0-4197-dfab-9037669a4b5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |â–ˆ                               | 10 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆ                              | 20 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆ                             | 30 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 40 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 81 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 92 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹              | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹             | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 316 kB 5.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download floret vectors\n",
        "! wget -nc https://github.com/explosion/spacy-vectors-builder/releases/download/en-3.4.0/en_vectors_floret_md.floret.gz"
      ],
      "metadata": {
        "id": "CYu84PJHRyor",
        "outputId": "3d78308c-dc6f-4680-b845-e6bab3f24088",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-01 14:22:55--  https://github.com/explosion/spacy-vectors-builder/releases/download/en-3.4.0/en_vectors_floret_md.floret.gz\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/468670482/dea3b10f-1c47-47f0-841e-542650ab9d80?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T142256Z&X-Amz-Expires=300&X-Amz-Signature=d9d8a4b5826f71e6ced283978140bb98ede161a80d40bfdd0d55ca9e4f86e868&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=468670482&response-content-disposition=attachment%3B%20filename%3Den_vectors_floret_md.floret.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-01 14:22:56--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/468670482/dea3b10f-1c47-47f0-841e-542650ab9d80?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T142256Z&X-Amz-Expires=300&X-Amz-Signature=d9d8a4b5826f71e6ced283978140bb98ede161a80d40bfdd0d55ca9e4f86e868&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=468670482&response-content-disposition=attachment%3B%20filename%3Den_vectors_floret_md.floret.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47586560 (45M) [application/octet-stream]\n",
            "Saving to: â€˜en_vectors_floret_md.floret.gzâ€™\n",
            "\n",
            "en_vectors_floret_m 100%[===================>]  45.38M   167MB/s    in 0.3s    \n",
            "\n",
            "2022-11-01 14:22:56 (167 MB/s) - â€˜en_vectors_floret_md.floret.gzâ€™ saved [47586560/47586560]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# spacy initialize them internally\n",
        "! spacy init vectors en en_vectors_floret_md.floret.gz en_vectors_floret_md --mode floret"
      ],
      "metadata": {
        "id": "yOCS-EeQR3vd",
        "outputId": "18c442a1-1fa7-4da4-8973-5dc584a6830d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-01 14:23:41.056906: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[38;5;4mâ„¹ Creating blank nlp object for language 'en'\u001b[0m\n",
            "[2022-11-01 14:23:42,080] [INFO] Reading vectors from en_vectors_floret_md.floret.gz\n",
            "INFO:spacy:Reading vectors from en_vectors_floret_md.floret.gz\n",
            "50000it [00:03, 13114.75it/s]\n",
            "[2022-11-01 14:23:45,982] [INFO] Loaded vectors from en_vectors_floret_md.floret.gz\n",
            "INFO:spacy:Loaded vectors from en_vectors_floret_md.floret.gz\n",
            "\u001b[38;5;2mâœ” Successfully converted 50000 vectors\u001b[0m\n",
            "\u001b[38;5;2mâœ” Saved nlp object with vectors to output directory. You can now use\n",
            "the path to it in your config as the 'vectors' setting in [initialize].\u001b[0m\n",
            "/content/en_vectors_floret_md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the spaCy pipeline with floret vectors\n",
        "nlp_fl = spacy.load(\"en_vectors_floret_md\")"
      ],
      "metadata": {
        "id": "5tPCNauPR7FK"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "how are these vectors different from standard spacy?\n",
        "the difference lies in OOV (out of vocabulary) words. Such words can occur where there are jargon or typos. Standard vecs in spacy contain a many 10k vocabularies. However, not everything can be covered"
      ],
      "metadata": {
        "id": "ps8-nijNc07o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_1 = nlp.vocab[\"univercities\"]\n",
        "word_2 = nlp.vocab[\"universities\"]\n",
        "\n",
        "word_1.similarity(word_2)"
      ],
      "metadata": {
        "id": "CCMEd3ncSHm9",
        "outputId": "601bcd5c-09e4-4764-82bd-f374ee3ab1a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: [W008] Evaluating Lexeme.similarity based on empty vectors.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# typo --> 0-vector\n",
        "word_1.vector"
      ],
      "metadata": {
        "id": "XZc2MPnHSOmS",
        "outputId": "1659ac3f-cc9a-4aa8-9277-6aeadf0951ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Floret vectors will also rely on \n",
        "`<univ', 'unive', 'niver', 'iverc', 'verci', 'ercit', 'rciti', 'citie', 'ities', 'ties>` and get it closer to right..."
      ],
      "metadata": {
        "id": "ngU7v7wNdPED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_1 = nlp_fl.vocab[\"univercities\"]\n",
        "word_2 = nlp_fl.vocab[\"universities\"]\n",
        "\n",
        "word_1.similarity(word_2)"
      ],
      "metadata": {
        "id": "kikMFacVSa0J",
        "outputId": "b3ef8305-b253-4a1b-9819-e03109764306",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7986329197883606"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_1.vector"
      ],
      "metadata": {
        "id": "V9yY71axSg01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.vstack([txt.vector for txt in nlp_fl.pipe(training_df.txt, disable=[\"parser\", \"ner\"])])"
      ],
      "metadata": {
        "id": "CsBLufH5SvUC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fl = LogisticRegression()"
      ],
      "metadata": {
        "id": "3BecPqZ3S8IB"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fl.fit(X_train, training_df.label)"
      ],
      "metadata": {
        "id": "ZRTVEuVcTBKu",
        "outputId": "4e53de92-8e1e-4c6c-8461-e1d96988669a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bot_name = 'ðŸŒ¸ Floret Jeppe'"
      ],
      "metadata": {
        "id": "RQSxFZnNTR6Y"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reply_fl(txt):\n",
        "  tag = model_fl.predict([nlp_fl(txt).vector])[0]\n",
        "  for intent in data['intents']:\n",
        "    if tag == intent[\"tag\"]:\n",
        "      print(f\"{bot_name}: {random.choice(intent['responses'])}\")"
      ],
      "metadata": {
        "id": "5QmzneFaTR6Z"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply_fl('which day does my stuff arrive?')"
      ],
      "metadata": {
        "id": "z29jE39ATR6Z",
        "outputId": "e05c7d73-8246-4f2a-e3cc-6dc08fee84c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŒ¸ Floret Jeppe: Delivery takes 2-4 days\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Chatbot command-line style"
      ],
      "metadata": {
        "id": "Sy5V_zPG6XxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bot_name = \"ðŸŒ¸ Floret Hugo\"\n",
        "your_name = \"ðŸŽƒ RJ\"\n",
        "\n",
        "\n",
        "print(\"Let's chat! (type 'quit' to exit)\")\n",
        "while True:\n",
        "    # sentence = \"do you use credit cards?\"\n",
        "    sentence = input(f\"{your_name}: \")\n",
        "    if sentence == \"quit\":\n",
        "        break\n",
        "    reply_fl(sentence)"
      ],
      "metadata": {
        "id": "DKH3OiPK6SBu",
        "outputId": "97af48bf-1d5b-498e-f8af-9521a045f14f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's chat! (type 'quit' to exit)\n",
            "ðŸŽƒ RJ: Hey\n",
            "ðŸŒ¸ Floret Hugo: Hi there, how can I help?\n",
            "ðŸŽƒ RJ: what do you sell?\n",
            "ðŸŒ¸ Floret Hugo: We sell coffee and tea\n",
            "ðŸŽƒ RJ: how can I pay?\n",
            "ðŸŒ¸ Floret Hugo: We accept VISA, Mastercard and Paypal\n",
            "ðŸŽƒ RJ: how long do you ship?\n",
            "ðŸŒ¸ Floret Hugo: Delivery takes 2-4 days\n",
            "ðŸŽƒ RJ: OK, thanks\n",
            "ðŸŒ¸ Floret Hugo: Bye! Come back again soon.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-27df2a03b39e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# sentence = \"do you use credit cards?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{your_name}: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         )\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chatbot app with streamlit:\n",
        "\n",
        "There is an extension which allows to implement a chatbot in ST:\n",
        "https://ai-yash-st-chat-exampleschatbot-fkuecs.streamlitapp.com/\n",
        "\n",
        "Example code can be found here:\n",
        "https://github.com/AI-Yash/st-chat/blob/main/examples/chatbot.py\n",
        "\n",
        "The bot in the example runs a rather fancy online deployed model by FB that actually evaluates the whole dialogue rather than individual sentences. Also, you would need to understand session states and a few other things to run that..."
      ],
      "metadata": {
        "id": "7WcxerG08MCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## On vectors"
      ],
      "metadata": {
        "id": "6CAA315M-b43"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wait, hold on, where do such vectors come from? Well, they are pretrained form large text-collections in a \"self-supervised\" fashion. The idea comes from [Word2Vec](https://proceedings.neurips.cc/paper/2013/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html) and related approaches, popular starting 2013. The idea here is to take text i.e. sentences and challenge a model to learn context, e.g. predict the \"masked\" next word from a sequence of words â‡’ Copenhagen is the [MASK] of Denmark."
      ],
      "metadata": {
        "id": "RQosMfrsdbOR"
      }
    }
  ]
}