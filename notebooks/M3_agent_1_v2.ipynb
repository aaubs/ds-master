{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaubs/ds-master/blob/main/notebooks/M3_agent_1_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXhpmxT66jdC"
      },
      "source": [
        "# Agents \n",
        "\n",
        "Agents are like \"tools\" for LLMs. They allow an LLM to access Google search, perform complex calculations with Python, and even make SQL queries.\n",
        "\n",
        "In this notebook, we'll explore agents and how to use them in LangChain.\n",
        "\n",
        "We'll start by installing the prerequisite libraries that we'll be using in this example."
      ],
      "id": "jXhpmxT66jdC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Built-in Agents in LangChain\n",
        "\n",
        "| **Agent Type**             | **Description**                                                                                                                                                   | **How to Build**                                                                                                                                                      | **Tools Used**                     |\n",
        "|-----------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------|\n",
        "| **Zero Shot React**         | An agent that uses an LLM to determine actions without prior context or memory. Suitable for tasks that don't require conversation history or complex reasoning.  | Use `create_sql_agent` with `SQLDatabaseToolkit`, specifying `agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION`.                                                     | `SQLDatabaseToolkit`               |\n",
        "| **Conversational React**    | An agent capable of maintaining conversation history and reasoning over previous interactions. Ideal for interactive applications that require memory.            | Use `initialize_agent` with `AgentType.CONVERSATIONAL_REACT_DESCRIPTION`, include a memory like `ConversationBufferMemory`, and load necessary tools (e.g., llm-math). | `llm-math` tool, `ConversationBufferMemory` |\n",
        "| **React Docstore**          | An agent that interacts with a docstore to search and retrieve information. Useful for answering questions based on documents or databases.                      | Use `initialize_agent` with `AgentType.REACT_DOCSTORE`, and include tools like `WikipediaAPIWrapper` for document retrieval.                                         | `WikipediaAPIWrapper`              |\n",
        "| **Self Ask with Search**    | An agent that decomposes questions into sub-questions and uses a search engine to find intermediate answers, leading to a final answer. Best for queries requiring external information. | Use `initialize_agent` with `AgentType.SELF_ASK_WITH_SEARCH`, and include search tools like `SerpAPIWrapper`. Note: Requires an API key for the search service.       | `SerpAPIWrapper` (Search Tool)     |\n",
        "| **Plan and Execute**        | An agent that creates a plan of actions to achieve a goal before executing them sequentially. Useful for complex tasks requiring multi-step reasoning.            | Use `initialize_agent` with `AgentType.PLAN_AND_EXECUTE`, and include necessary tools for executing each step of the plan.                                           | Various execution tools             |\n",
        "| **Agent Executor**          | A generic agent that can execute a series of tools based on the input prompt and internal logic. Versatile for multiple use cases.                              | Use `initialize_agent` with `AgentType.EXECUTOR`, and configure with desired tools and logic.                                                                          | Various tools based on use case     |\n",
        "| **Agent Synthesis**         | An agent that synthesizes information from multiple sources to provide comprehensive answers. Ideal for aggregating data from various APIs or databases.         | Use `initialize_agent` with `AgentType.SYNTHESIS`, and include tools that access different data sources.                                                                | Multiple data access tools          |\n",
        "| **Dynamic Agent**           | An agent that dynamically selects tools and actions based on the context and requirements of the task.                                                        | Use `initialize_agent` with `AgentType.DYNAMIC`, and set up conditional logic for tool selection.                                                                       | Conditional tools logic             |\n",
        "| **Tool Use Agent**          | An agent designed to utilize a predefined set of tools to perform specific tasks. Ideal for automating workflows that require tool interactions.                 | Use `initialize_agent` with `AgentType.TOOL_USE`, and specify the tools to be integrated.                                                                              | Predefined set of tools             |\n",
        "| **ReAct**                   | An agent that combines reasoning and acting, allowing it to perform tasks that require both understanding and executing actions based on that understanding.     | Use `initialize_agent` with `AgentType.REACT`, and integrate tools that support reasoning and action execution.                                                        | Reasoning and action execution tools|\n",
        "| **Agent Zero-Shot**         | Similar to Zero Shot React but optimized for scenarios requiring minimal configuration and quick deployment without extensive customization.                   | Use `create_agent` with `AgentType.ZERO_SHOT`, focusing on default settings for rapid implementation.                                                                    | Minimal configuration tools         |\n",
        "\n",
        "---\n",
        "\n",
        "**Notes:**\n",
        "\n",
        "- **Tool Integration:** Each agent type utilizes specific tools tailored to its functionality. Ensure that the necessary tools are installed and properly configured in your environment.\n",
        "  \n",
        "- **API Keys:** Some agents, especially those involving search functionalities like `Self Ask with Search`, may require API keys. Make sure to obtain and securely store any required credentials.\n",
        "  \n",
        "- **Customization:** While these agents come built-in, LangChain allows for extensive customization. You can extend or modify agents to better fit your specific use cases.\n",
        "\n",
        "- **Documentation:** For the most up-to-date and detailed information, always refer to the [official LangChain documentation](https://langchain.readthedocs.io/).\n",
        "\n"
      ],
      "metadata": {
        "id": "44bkC4yD8b-P"
      },
      "id": "44bkC4yD8b-P"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxPSD_vd6jdE",
        "outputId": "63b48e20-840d-4d68-bfdd-789a172ecd1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m389.5/389.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain openai sqlalchemy wikipedia langchain_community --q"
      ],
      "id": "oxPSD_vd6jdE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo7hRx_r6jdE"
      },
      "source": [
        "To run this notebook, we will need to use an OpenAI LLM. Here we will set up the LLM we will use for the whole notebook. Just input your OpenAI API key when prompted."
      ],
      "id": "fo7hRx_r6jdE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-WOVw846jdF",
        "outputId": "f1ef2073-dc83-4aa2-88c9-173bb8e2496f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key:路路路路路路路路路路\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass(\"Enter your OpenAI API key:\")"
      ],
      "id": "r-WOVw846jdF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEapin1z6jdF"
      },
      "source": [
        "Now, we can initialize the LLM."
      ],
      "id": "dEapin1z6jdF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSKWbUyL6jdF",
        "outputId": "fd516ac6-e768-44d5-c8b5-3759ff86aa26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-9e0b12c5cbe2>:3: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  llm = OpenAI(\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    temperature=0\n",
        ")"
      ],
      "id": "lSKWbUyL6jdF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PdEIOaj6jdF"
      },
      "source": [
        "As we did before, we will be counting our tokens in each call."
      ],
      "id": "3PdEIOaj6jdF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keo-QjEv6jdF"
      },
      "outputs": [],
      "source": [
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "def count_tokens(agent, query):\n",
        "    with get_openai_callback() as cb:\n",
        "        result = agent(query)\n",
        "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
        "    return result"
      ],
      "id": "keo-QjEv6jdF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOPxjzSl6jdG"
      },
      "source": [
        "With all of that set up, let's jump into Agents.\n",
        "\n",
        "## What is an agent?\n",
        "\n",
        "**Definition:** The key behind agents is giving LLMs the possibility of using tools in their workflow. This is where LangChain departs from the popular ChatGPT implementation and we can start to get a glimpse of what it offers us as builders. Until now, we covered several building blocks in isolation. Let's see them come to life.\n",
        "\n",
        "The official definition of agents is the following:\n",
        "\n",
        "**Agents use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output or returning to the user.**\n",
        "\n",
        "In this notebook, we will cover several types of agents and see how they 'think' and what they can do."
      ],
      "id": "wOPxjzSl6jdG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNcR6s5R6jdG"
      },
      "source": [
        "## Create a Database\n",
        "\n",
        "We will use the agents to interact with a small sample database of movies. We will not dive into the details because this is just a dummy tool we will build for illustrative purposes. Let's create it.\n",
        "\n",
        "First, we create the database schema."
      ],
      "id": "dNcR6s5R6jdG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8tczq2O6jdG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Sample Movies Data\n",
        "movies_data = [\n",
        "    {'id': 1, 'title': 'The Shawshank Redemption', 'director': 'Frank Darabont', 'year': 1994, 'genre': 'Drama', 'rating': 9.3},\n",
        "    {'id': 2, 'title': 'The Godfather', 'director': 'Francis Ford Coppola', 'year': 1972, 'genre': 'Crime', 'rating': 9.2},\n",
        "    {'id': 3, 'title': 'The Dark Knight', 'director': 'Christopher Nolan', 'year': 2008, 'genre': 'Action', 'rating': 9.0},\n",
        "    {'id': 4, 'title': 'Pulp Fiction', 'director': 'Quentin Tarantino', 'year': 1994, 'genre': 'Crime', 'rating': 8.9},\n",
        "    {'id': 5, 'title': 'The Lord of the Rings: The Return of the King', 'director': 'Peter Jackson', 'year': 2003, 'genre': 'Adventure', 'rating': 8.9},\n",
        "    {'id': 6, 'title': \"Schindler's List\", 'director': 'Steven Spielberg', 'year': 1993, 'genre': 'Biography', 'rating': 8.9},\n",
        "    {'id': 7, 'title': 'Forrest Gump', 'director': 'Robert Zemeckis', 'year': 1994, 'genre': 'Drama', 'rating': 8.8},\n",
        "    {'id': 8, 'title': 'Inception', 'director': 'Christopher Nolan', 'year': 2010, 'genre': 'Action', 'rating': 8.8},\n",
        "    {'id': 9, 'title': 'Fight Club', 'director': 'David Fincher', 'year': 1999, 'genre': 'Drama', 'rating': 8.8},\n",
        "    {'id': 10, 'title': 'The Matrix', 'director': 'Lana Wachowski, Lilly Wachowski', 'year': 1999, 'genre': 'Sci-Fi', 'rating': 8.7}\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "df_movies = pd.DataFrame(movies_data)\n",
        "\n",
        "# Database Configuration\n",
        "DATABASE_URL = \"sqlite:///movies.db\"  # SQLite database file named 'movies.db'\n",
        "\n",
        "# Create SQLAlchemy Engine\n",
        "engine = create_engine(DATABASE_URL, echo=True)  # echo=True enables SQL logging\n",
        "\n",
        "# Insert DataFrame into 'movies' Table\n",
        "df_movies.to_sql('movies', con=engine, if_exists='replace', index=False)\n",
        "\n",
        "# Read Data Back into a DataFrame\n",
        "df_result = pd.read_sql('SELECT * FROM movies', con=engine)\n",
        "\n",
        "# Display the DataFrame\n",
        "df_result"
      ],
      "id": "j8tczq2O6jdG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBVW7Lzc6jdH"
      },
      "source": [
        "## Agent Types\n",
        "\n",
        "In this section, we will review several agents and see how they 'think' and what they can do.\n",
        "\n",
        "Using one of LangChain's pre-built agents involves three variables:\n",
        "\n",
        "1. Defining the tools or the toolkit\n",
        "2. Defining the LLM\n",
        "3. Defining the agent type"
      ],
      "id": "wBVW7Lzc6jdH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3PHDLhR6jdH"
      },
      "source": [
        "### Agent Type #1: Zero Shot React\n",
        "\n",
        "In this first example, we will use the Zero Shot React agent to interact with our movies database.\n",
        "\n",
        "We will use the `create_sql_agent` function. This method uses a toolkit instead of a simple list of tools.\n",
        "\n",
        "Now we are ready to initialize the agent! We will use `verbose=True` so we can see what our agent's 'thinking' process.\n",
        "\n",
        "**Important Note:** When interacting with agents, it is really important to set the `max_iterations` parameter because agents can get stuck in infinite loops that consume plenty of tokens. The default value is 15 to allow for many tools and complex reasoning, but for most applications, you should keep it much lower."
      ],
      "id": "b3PHDLhR6jdH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05tlB02C6jdH"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.utilities import SQLDatabase\n",
        "\n",
        "db = SQLDatabase(engine)\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "\n",
        "agent_executor = create_sql_agent(\n",
        "    llm=llm,\n",
        "    toolkit=toolkit,\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    max_iterations=2\n",
        ")\n"
      ],
      "id": "05tlB02C6jdH"
    },
    {
      "cell_type": "code",
      "source": [
        "tables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"  # Use SQLite syntax to get table names\n",
        "result = db.run(tables_query)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucynl62-IOBl",
        "outputId": "4d4f4a0d-e221-4549-d7ae-ddc7ee18cb33"
      },
      "id": "ucynl62-IOBl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('movies',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "records_query = \"SELECT * FROM movies LIMIT 10;\"  # Replace 'table_name' with the actual table name\n",
        "records_result = db.run(records_query)\n",
        "print(records_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS1FVRLHIO7p",
        "outputId": "7c27a7bf-dc4a-4ea3-ae2f-74dccdd3c86b"
      },
      "id": "IS1FVRLHIO7p",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE83gU216jdH"
      },
      "source": [
        "Let's see our newly created agent in action! We will ask it a question that involves an aggregation over the movie ratings."
      ],
      "id": "bE83gU216jdH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PngbbleG6jdH",
        "outputId": "d5599352-1767-4f53-f906-b6a8d7ea8eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input: \u001b[0m\u001b[38;5;200m\u001b[1;3mmovies\u001b[0m\u001b[32;1m\u001b[1;3mI should query the schema of the movies table to see what columns I can use.\n",
            "Action: sql_db_schema\n",
            "Action Input: movies\u001b[0m2024-11-16 09:10:36,675 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:sqlalchemy.engine.Engine:BEGIN (implicit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-16 09:10:36,680 INFO sqlalchemy.engine.Engine SELECT movies.id, movies.title, movies.director, movies.year, movies.genre, movies.rating \n",
            "FROM movies\n",
            " LIMIT ? OFFSET ?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:sqlalchemy.engine.Engine:SELECT movies.id, movies.title, movies.director, movies.year, movies.genre, movies.rating \n",
            "FROM movies\n",
            " LIMIT ? OFFSET ?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-16 09:10:36,684 INFO sqlalchemy.engine.Engine [generated in 0.00902s] (3, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:sqlalchemy.engine.Engine:[generated in 0.00902s] (3, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-16 09:10:36,687 INFO sqlalchemy.engine.Engine ROLLBACK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:sqlalchemy.engine.Engine:ROLLBACK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE movies (\n",
            "\tid INTEGER NOT NULL, \n",
            "\ttitle VARCHAR NOT NULL, \n",
            "\tdirector VARCHAR NOT NULL, \n",
            "\tyear INTEGER NOT NULL, \n",
            "\tgenre VARCHAR NOT NULL, \n",
            "\trating FLOAT NOT NULL, \n",
            "\tPRIMARY KEY (id)\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from movies table:\n",
            "id\ttitle\tdirector\tyear\tgenre\trating\n",
            "1\tThe Shawshank Redemption\tFrank Darabont\t1994\tDrama\t9.3\n",
            "2\tThe Godfather\tFrancis Ford Coppola\t1972\tCrime\t9.2\n",
            "3\tThe Dark Knight\tChristopher Nolan\t2008\tAction\t9.0\n",
            "*/\u001b[0m\u001b[32;1m\u001b[1;3m I should query the movies table to get the average rating for each director.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT director, AVG(rating) FROM movies GROUP BY director ORDER BY AVG(rating) DESC LIMIT 10\u001b[0m2024-11-16 09:10:37,944 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:sqlalchemy.engine.Engine:BEGIN (implicit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-16 09:10:37,948 INFO sqlalchemy.engine.Engine SELECT director, AVG(rating) FROM movies GROUP BY director ORDER BY AVG(rating) DESC LIMIT 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:sqlalchemy.engine.Engine:SELECT director, AVG(rating) FROM movies GROUP BY director ORDER BY AVG(rating) DESC LIMIT 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-16 09:10:37,953 INFO sqlalchemy.engine.Engine [generated in 0.00521s] ()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:sqlalchemy.engine.Engine:[generated in 0.00521s] ()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-16 09:10:37,957 INFO sqlalchemy.engine.Engine COMMIT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:sqlalchemy.engine.Engine:COMMIT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36;1m\u001b[1;3m[('Frank Darabont', 9.3), ('Francis Ford Coppola', 9.2), ('Steven Spielberg', 8.9), ('Quentin Tarantino', 8.9), ('Peter Jackson', 8.9), ('Christopher Nolan', 8.9), ('Robert Zemeckis', 8.8), ('David Fincher', 8.8), ('Lana Wachowski, Lilly Wachowski', 8.7)]\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: Frank Darabont\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Spent a total of 0 tokens\n"
          ]
        }
      ],
      "source": [
        "result = count_tokens(\n",
        "    agent_executor,\n",
        "    \"Which director has the highest average movie rating?\"\n",
        ")\n"
      ],
      "id": "PngbbleG6jdH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URMbec5E6jdH"
      },
      "source": [
        "**Sample Output:**\n",
        "\n",
        "```vbnet\n",
        "> Entering new AgentExecutor chain...\n",
        "Thought: I need to query the database to find the average rating per director and then find the director with the highest average rating.\n",
        "Action: query_sql_db\n",
        "Action Input: SELECT director, AVG(rating) as avg_rating FROM movies GROUP BY director ORDER BY avg_rating DESC LIMIT 1;\n",
        "\n",
        "Observation: [('Frank Darabont', 9.3)]\n",
        "Thought: I have the result.\n",
        "Final Answer: Frank Darabont has the highest average movie rating.\n",
        "\n",
        "> Finished chain.\n",
        "Spent a total of 150 tokens\n",
        "```\n"
      ],
      "id": "URMbec5E6jdH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii7ixhZw6jdH"
      },
      "source": [
        "### Agent Type #2: Conversational React\n",
        "\n",
        "The Zero Shot agent is interesting but has no memory. What if we want an assistant that remembers things we have talked about and can also reason about them and use tools? For that, we have the Conversational React agent.\n",
        "\n",
        "We will use the math tool in this example and load it as below:"
      ],
      "id": "Ii7ixhZw6jdH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc2RCWgw6jdH",
        "outputId": "eae84935-fd7a-477a-a8b2-8a2b9779a22d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-f172c9865266>:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
            "<ipython-input-33-f172c9865266>:9: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
            "  conversational_agent = initialize_agent(\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.agents.agent_types import AgentType\n",
        "\n",
        "tools = load_tools([\"llm-math\"], llm=llm)\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "\n",
        "conversational_agent = initialize_agent(\n",
        "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=2,\n",
        "    memory=memory\n",
        ")"
      ],
      "id": "Uc2RCWgw6jdH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl0K0j0p6jdH"
      },
      "source": [
        "Now, let's have a conversation with our agent.\n",
        "\n",
        "First, we ask a math question."
      ],
      "id": "Pl0K0j0p6jdH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6SQ1oil6jdH",
        "outputId": "5e631931-1eef-4f95-9c3e-f6647844e5be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Thought: Do I need to use a tool? Yes\n",
            "Action: Calculator\n",
            "Action Input: Average of 8.5, 9.0, and 7.5\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 8.333333333333334\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
            "AI: The average rating of the three movies is 8.333333333333334.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Spent a total of 1160 tokens\n"
          ]
        }
      ],
      "source": [
        "result = count_tokens(\n",
        "    conversational_agent,\n",
        "    \"If I have 3 movies rated 8.5, 9.0, and 7.5, what is their average rating?\"\n",
        ")\n"
      ],
      "id": "l6SQ1oil6jdH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTii6bWV6jdH"
      },
      "source": [
        "**Sample Output:**\n",
        "\n",
        "```vbnet\n",
        "> Entering new AgentExecutor chain...\n",
        "Thought: I need to calculate the average of the three ratings.\n",
        "Action: Calculator\n",
        "Action Input: (8.5 + 9.0 + 7.5) / 3\n",
        "Observation: Answer: 8.333333333333334\n",
        "Thought: I now have the average rating.\n",
        "AI: The average rating of the three movies is approximately 8.33.\n",
        "\n",
        "> Finished chain.\n",
        "Spent a total of 132 tokens\n",
        "```\n"
      ],
      "id": "ZTii6bWV6jdH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekHVRh196jdH"
      },
      "source": [
        "Then, let's ask a follow-up question."
      ],
      "id": "ekHVRh196jdH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nqVBrIe6jdI",
        "outputId": "1df48ad5-fd3c-42d7-f728-3722e0c1319e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Calculator\n",
            "Action Input: (8.5 + 9.0 + 7.5 + 9.5) / 4\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 8.625\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
            "AI: The new average rating will be 8.625.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Spent a total of 1261 tokens\n"
          ]
        }
      ],
      "source": [
        "result = count_tokens(\n",
        "    conversational_agent,\n",
        "    \"If I watch another movie rated 9.5, what will be the new average rating?\"\n",
        ")\n"
      ],
      "id": "6nqVBrIe6jdI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfmC-nQA6jdI"
      },
      "source": [
        "**Sample Output:**\n",
        "\n",
        "```vbnet\n",
        "> Entering new AgentExecutor chain...\n",
        "Thought: I should add the new rating and recalculate the average.\n",
        "Action: Calculator\n",
        "Action Input: (8.5 + 9.0 + 7.5 + 9.5) / 4\n",
        "Observation: Answer: 8.625\n",
        "Thought: I have the new average rating.\n",
        "AI: The new average rating after watching the fourth movie is 8.625.\n",
        "\n",
        "> Finished chain.\n",
        "Spent a total of 142 tokens\n",
        "```\n"
      ],
      "id": "VfmC-nQA6jdI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGtoqEuz6jdI"
      },
      "source": [
        "This demonstrates the agent's ability to remember previous interactions and use tools to perform calculations."
      ],
      "id": "dGtoqEuz6jdI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x1A1wCQ6jdI"
      },
      "source": [
        "### Agent Type #3: React Docstore\n",
        "\n",
        "This type of agent is similar to the ones we have seen so far but it includes the interaction with a docstore. It will have tools at its disposal to search and retrieve information.\n",
        "\n",
        "Let's use the Wikipedia tool to answer questions."
      ],
      "id": "7x1A1wCQ6jdI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmvedzKk6jdI"
      },
      "outputs": [],
      "source": [
        "from langchain import Wikipedia\n",
        "from langchain.agents.react.base import DocstoreExplorer, Tool\n",
        "\n",
        "docstore = DocstoreExplorer(Wikipedia())\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Search\",\n",
        "        func=docstore.search,\n",
        "        description='search wikipedia'\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Lookup\",\n",
        "        func=docstore.lookup,\n",
        "        description='lookup a term in wikipedia'\n",
        "    )\n",
        "]"
      ],
      "id": "ZmvedzKk6jdI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su9F1keV6jdI"
      },
      "source": [
        "Now, let's ask a question."
      ],
      "id": "Su9F1keV6jdI"
    },
    {
      "cell_type": "code",
      "source": [
        "docstore_agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=\"react-docstore\",\n",
        "    verbose=True,\n",
        "    max_iterations=2\n",
        ")"
      ],
      "metadata": {
        "id": "OSzoWoFdSzkw"
      },
      "id": "OSzoWoFdSzkw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue0CglfL6jdI",
        "outputId": "86e743ab-8f91-487f-a91a-e079a0ea4e5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to search Inception, find its director, then find other popular movies made by the director.\n",
            "Action: Search[Inception]\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mCould not find [Inception]. Similar: ['Inception', 'Inception (disambiguation)', 'Inception (soundtrack)', 'Peugeot Inception', 'Fr茅chet inception distance', 'Inception (deep learning architecture)', 'Into Inception', 'Ultimate tic-tac-toe', 'Nvidia', 'List of accolades received by Inception']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to search Inception (film) instead.\n",
            "Action: Search[Inception (film)]\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mInception is a 2010 science fiction  action  heist  film written and directed by Christopher Nolan, who also produced it with Emma Thomas, his wife. The film stars Leonardo DiCaprio as a professional thief who steals information by infiltrating the subconscious of his targets. He is offered a chance to have his criminal history erased as payment for the implantation of another person's idea into a target's subconscious. The ensemble cast includes Ken Watanabe, Joseph Gordon-Levitt, Marion Cotillard, Elliot Page, Tom Hardy, Cillian Murphy, Tom Berenger, Dileep Rao, and Michael Caine.\n",
            "After the 2002 completion of Insomnia, Nolan presented to Warner Bros. a written 80-page treatment for a horror film envisioning \"dream stealers,\" based on lucid dreaming. Deciding he needed more experience before tackling a production of this magnitude and complexity, Nolan shelved the project and instead worked on 2005's Batman Begins, 2006's The Prestige, and 2008's The Dark Knight. The treatment was revised over six months and was purchased by Warner in February 2009. Inception was filmed in six countries, beginning in Tokyo on June 19 and ending in Canada on November 22. Its official budget was $160 million, split between Warner Bros. and Legendary. Nolan's reputation and success with The Dark Knight helped secure the film's US$100 million in advertising expenditure.\n",
            "Inception's premiere was held in London on July 8, 2010; it was released in both conventional and IMAX theaters beginning on July 16, 2010. Inception grossed over $837 million worldwide, becoming the fourth-highest-grossing film of 2010. Considered one of the best films of the 2010s, Inception won four Oscars (Best Cinematography, Best Sound Editing, Best Sound Mixing, Best Visual Effects) and was nominated for four more (Best Picture, Best Original Screenplay, Best Art Direction, Best Original Score) at the 83rd Academy Awards.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Spent a total of 2923 tokens\n"
          ]
        }
      ],
      "source": [
        "result = count_tokens(\n",
        "    docstore_agent,\n",
        "    \"Who directed 'Inception' and what other popular movies has this director made?\"\n",
        ")\n"
      ],
      "id": "Ue0CglfL6jdI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlipKj4k6jdI"
      },
      "source": [
        "**Sample Output:**\n",
        "\n",
        "```vbnet\n",
        "> Entering new AgentExecutor chain...\n",
        "Thought: I need to find out who directed 'Inception' and then find other movies by the same director.\n",
        "Action: Wikipedia\n",
        "Action Input: Inception\n",
        "Observation: \"Inception\" is a 2010 science fiction action film written and directed by Christopher Nolan...\n",
        "Thought: The director is Christopher Nolan. Now I need to find other popular movies by him.\n",
        "Action: Wikipedia\n",
        "Action Input: Christopher Nolan filmography\n",
        "Observation: Christopher Nolan has directed films like 'Memento', 'The Dark Knight', 'Interstellar', and 'Dunkirk'.\n",
        "Thought: I have the information now.\n",
        "Final Answer: 'Inception' was directed by Christopher Nolan. Other popular movies he has directed include 'Memento', 'The Dark Knight', 'Interstellar', and 'Dunkirk'.\n",
        "\n",
        "> Finished chain.\n",
        "Spent a total of 352 tokens\n",
        "```\n"
      ],
      "id": "xlipKj4k6jdI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwf1A1ED6jdI"
      },
      "source": [
        "This shows how the agent uses Wikipedia to find information about Christopher Nolan and mentions other popular movies he has directed."
      ],
      "id": "gwf1A1ED6jdI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfsGw8bb6jdI"
      },
      "source": [
        "### Agent Type #4: Self Ask with Search\n",
        "\n",
        "This is the first-choice agent to use when using LLMs to extract information with a search engine. The agent will ask follow-up questions and use the search functionality to get intermediate answers that help it get to a final answer.\n",
        "\n",
        "Considering the image below, it is evident that Self-Ask Prompting is a progression from Direct and Chain-Of-Thought prompting.\n",
        "\n",
        "The interesting thing about self-ask prompting is that the LLM reasoning is shown explicitly and the LLM also decomposes the question into smaller follow-up questions.\n",
        "\n",
        "The LLM knows when the final answer is reached and can move from follow up intermediate answers to a final answer."
      ],
      "id": "HfsGw8bb6jdI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5R8lx3gTlEjvvHoSs0Gjhg.png)"
      ],
      "metadata": {
        "id": "_iH42nstSmel"
      },
      "id": "_iH42nstSmel"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the `SerpAPIWrapper` to perform searches. Note that you need a SerpAPI key to use this tool."
      ],
      "metadata": {
        "id": "H2n6dkUCSic_"
      },
      "id": "H2n6dkUCSic_"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results openai langchain --q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74Cgx13WTiLx",
        "outputId": "3db5b75c-33a4-4832-94ee-78131356f469"
      },
      "id": "74Cgx13WTiLx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass(\"Enter your OpenAI API key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnEjNquPTT-H",
        "outputId": "9ac96f06-3cd4-4f3c-c7ad-44106d4a0f55"
      },
      "id": "CnEjNquPTT-H",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key:路路路路路路路路路路\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SERPAPI_API_KEY = getpass(\"Enter your SerpAPI API key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRvySKwETVpn",
        "outputId": "fd5a61d0-2c61-430e-8c93-c95444644230"
      },
      "id": "ZRvySKwETVpn",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your SerpAPI API key:路路路路路路路路路路\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"SERPAPI_API_KEY\"] = SERPAPI_API_KEY\n",
        "\n",
        "from langchain import OpenAI, SerpAPIWrapper\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents import AgentType\n",
        "\n",
        "llm = OpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    temperature=0\n",
        ")\n",
        "search = SerpAPIWrapper()\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Intermediate Answer\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to ask with search\",\n",
        "    )\n",
        "]\n",
        "\n",
        "self_ask_with_search = initialize_agent(\n",
        "    tools, llm, agent=AgentType.SELF_ASK_WITH_SEARCH, verbose=True\n",
        ")\n",
        "self_ask_with_search.run(\n",
        "    \"What is the hometown of the reigning men's U.S. Open champion?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "CgIYQgLyS4Rz",
        "outputId": "550fb9fd-1cbd-43b1-b279-a91220bbbb36"
      },
      "id": "CgIYQgLyS4Rz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-914424018aed>:22: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
            "  self_ask_with_search = initialize_agent(\n",
            "<ipython-input-11-914424018aed>:25: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  self_ask_with_search.run(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m Yes.\n",
            "Follow up: Who is the reigning men's U.S. Open champion?\u001b[0m\n",
            "Intermediate answer: \u001b[36;1m\u001b[1;3mJannik Sinner\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFollow up: Where is Jannik Sinner from?\u001b[0m\n",
            "Intermediate answer: \u001b[36;1m\u001b[1;3mJannik Sinner (born August 16, 2001, San Candido, Italy) is an Italian tennis player who is a leading star in the generation of players rising in the wake of the indomitable Big Three (Novak Djokovic, Roger Federer, and Rafael Nadal).\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mSo the final answer is: San Candido, Italy\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'San Candido, Italy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(self_ask_with_search.agent.llm_chain.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S3SKWdjTrbO",
        "outputId": "88f250cf-9b5f-425e-d685-5a094151f071"
      },
      "id": "2S3SKWdjTrbO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: How old was Muhammad Ali when he died?\n",
            "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
            "Follow up: How old was Alan Turing when he died?\n",
            "Intermediate answer: Alan Turing was 41 years old when he died.\n",
            "So the final answer is: Muhammad Ali\n",
            "\n",
            "Question: When was the founder of craigslist born?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the founder of craigslist?\n",
            "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
            "Follow up: When was Craig Newmark born?\n",
            "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
            "So the final answer is: December 6, 1952\n",
            "\n",
            "Question: Who was the maternal grandfather of George Washington?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the mother of George Washington?\n",
            "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
            "Follow up: Who was the father of Mary Ball Washington?\n",
            "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
            "So the final answer is: Joseph Ball\n",
            "\n",
            "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who is the director of Jaws?\n",
            "Intermediate answer: The director of Jaws is Steven Spielberg.\n",
            "Follow up: Where is Steven Spielberg from?\n",
            "Intermediate answer: The United States.\n",
            "Follow up: Who is the director of Casino Royale?\n",
            "Intermediate answer: The director of Casino Royale is Martin Campbell.\n",
            "Follow up: Where is Martin Campbell from?\n",
            "Intermediate answer: New Zealand.\n",
            "So the final answer is: No\n",
            "\n",
            "Question: {input}\n",
            "Are followup questions needed here:{agent_scratchpad}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cWt_8xW7Ajz-BJ0TSZ63Iw.png)"
      ],
      "metadata": {
        "id": "s47tvGBUYIAm"
      },
      "id": "s47tvGBUYIAm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xyhofv7L6jdJ"
      },
      "source": [
        "## Wrapping Up\n",
        "\n",
        "And that's all for agents! There's many other things you can do with agents, just to name a few:\n",
        "\n",
        "- Create your own custom agent\n",
        "- Use them with many other tools (even custom ones)\n",
        "- Trace every call an agent makes through a convenient UI interface\n",
        "- Check the how-to guides for more!\n",
        "\n",
        "In this modified notebook, we have replaced the previous stock database with a movies database, which is more engaging and interesting. We have also provided more tangible examples for each agent type, demonstrating their capabilities in a clear and understandable way.\n",
        "\n",
        "Feel free to experiment further and explore the vast possibilities that agents offer in LangChain!"
      ],
      "id": "Xyhofv7L6jdJ"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hwWshdKzX-nI"
      },
      "id": "hwWshdKzX-nI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}